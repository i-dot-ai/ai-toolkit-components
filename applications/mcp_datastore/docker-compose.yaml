services:
  vector_db:
    image: ghcr.io/i-dot-ai/ai-toolkit-vector-db:latest
    container_name: vector_db
    ports:
      - "${HTTP_PORT:-6333}:${HTTP_PORT:-6333}"  # HTTP API
      - "${GRPC_PORT:-6334}:${GRPC_PORT:-6334}"  # gRPC API
    volumes:
      - ./code/vector_db:/app/custom
      - qdrant_storage:/qdrant/storage
    environment:
      - HTTP_PORT
      - GRPC_PORT
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'

  data_ingestor:
    image: ghcr.io/i-dot-ai/ai-toolkit-data-ingestor:latest
    container_name: data_ingestor
    volumes:
      - ./code/data_ingestor:/app/custom
      - ./input:/input
    depends_on:
      - vector_db
    environment:
      - VECTOR_DB_HOST=vector_db
    # Example: ingest URLs by passing them as command arguments
    # e.g.: ["https://example.com", "https://example.com/page2"]
    # Or use a file: command: ["-f", "/app/sources.txt"]
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
          cpus: '0.5'

  mcp_server:
    image: ghcr.io/i-dot-ai/ai-toolkit-mcp-server:latest
    container_name: mcp_server
    ports:
      - "${MCP_PORT:-8080}:${MCP_PORT:-8080}"
    volumes:
      - ./code/mcp_server:/app/custom
    depends_on:
      - vector_db
    environment:
      - MCP_PORT
      - VECTOR_DB_HOST=vector_db
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
          cpus: '0.5'

volumes:
  qdrant_storage:
